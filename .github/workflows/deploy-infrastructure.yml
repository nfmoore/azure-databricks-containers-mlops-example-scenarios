name: Deploy Infrastructure

on:
  workflow_dispatch:

env:
  AZ_CLI_VERSION: 2.59.0
  DATABRICKS_CLUSTER_NAME: default
  DEPLOYMENT_NAME: validate-${{ github.run_id }}
  DEPLOYMENT_LOCATION: ${{ vars.DEPLOYMENT_LOCATION }}
  DEPLOYMENT_RESOURCE_GROUP_NAME: ${{ vars.DEPLOYMENT_RESOURCE_GROUP_NAME }}
  DEPLOYMENT_DATARBICKS_MANAGED_RESOURCE_GROUP_NAME: ${{ vars.DEPLOYMENT_DATARBICKS_MANAGED_RESOURCE_GROUP_NAME }}
  TEMPLATE_FILE: infrastructure/main.bicep
  DATABRICKS_HOST:
  DATABRICKS_TOKEN:
  DATABRICKS_CLUSTER_ID:

permissions:
  id-token: write
  contents: read

jobs:
  build:
    name: Bicep Build
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Authenticate to Az CLI using OIDC
      - name: "Azure CLI login"
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # Checks that all Bicep configuration files adhere to a canonical format
      - name: Bicep lint
        uses: azure/cli@v2
        with:
          azcliversion: ${{ env.AZ_CLI_VERSION }}
          inlineScript: az bicep build --file ${TEMPLATE_FILE}

      # Validate whether the template is valid at subscription scope
      - name: Bicep validate
        uses: azure/cli@v2
        with:
          azcliversion: ${{ env.AZ_CLI_VERSION }}
          inlineScript: |
            az deployment sub validate \
              --name validate-${DEPLOYMENT_NAME} \
              --template-file ${TEMPLATE_FILE} \
              --location ${DEPLOYMENT_LOCATION} \
              --parameters resourceGroupName=${DEPLOYMENT_RESOURCE_GROUP_NAME} \
              --parameters mrgDatabricksName=${DEPLOYMENT_DATARBICKS_MANAGED_RESOURCE_GROUP_NAME} \
              --parameters location=${DEPLOYMENT_LOCATION}

  deploy:
    name: Bicep Deploy
    runs-on: ubuntu-latest
    needs: [build]
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Authenticate to Az CLI using OIDC
      - name: "Azure CLI login"
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

        # Deploy template to subscription
      - name: "Bicep deployment"
        uses: azure/cli@v2
        with:
          azcliversion: ${{ env.AZ_CLI_VERSION }}
          inlineScript: |
            # Create artifacts directory
            mkdir artifacts

            # Deploy the Bicep template
            az deployment sub create \
              --name validate-${DEPLOYMENT_NAME} \
              --template-file ${TEMPLATE_FILE} \
              --location ${DEPLOYMENT_LOCATION} \
              --parameters resourceGroupName=${DEPLOYMENT_RESOURCE_GROUP_NAME} \
              --parameters mrgDatabricksName=${DEPLOYMENT_DATARBICKS_MANAGED_RESOURCE_GROUP_NAME} \
              --parameters location=${DEPLOYMENT_LOCATION} \
              > artifacts/deployment-output.json

      # Upload output from deployment
      - uses: actions/upload-artifact@v4
        with:
          name: artifacts
          path: artifacts

  setup:
    name: Databricks Setup
    runs-on: ubuntu-latest
    needs: [deploy]
    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout repo
        uses: actions/checkout@v4

      # Download output from deployment
      - uses: actions/download-artifact@v4
        with:
          name: artifacts

      # Authenticate to Az CLI using OIDC
      - name: "Azure CLI login"
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # Set Databricks host and token environment variables
      - name: Set Databricks environment variables
        uses: azure/cli@v2
        with:
          azcliversion: ${{ env.AZ_CLI_VERSION }}
          inlineScript: |
            echo "DATABRICKS_HOST=https://$(jq .properties.outputs.databricksHostname.value \
              deployment-output.json -r)" >> $GITHUB_ENV
              
            echo "DATABRICKS_TOKEN=$(az account get-access-token \
              --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d | jq .accessToken -r)" >> $GITHUB_ENV

      # Create Databricks cluster
      - name: Create Databricks cluster
        run: |
          # Create artifacts directory
          mkdir artifacts

          ls

          # Create Databricks cluster
          curl -X POST "$DATABRICKS_HOST/api/2.0/clusters/create" \
            -H "Authorization: Bearer $DATABRICKS_TOKEN" \
            -d '{
                "num_workers": 0,
                "cluster_name": "${DATABRICKS_CLUSTER_NAME}",
                "spark_version": "14.3.x-cpu-ml-scala2.12",
                "spark_conf": {
                    "spark.master": "local[*, 4]",
                    "spark.databricks.cluster.profile": "singleNode"
                },
                "azure_attributes": {
                    "first_on_demand": 1,
                    "availability": "ON_DEMAND_AZURE",
                    "spot_bid_max_price": -1
                },
                "node_type_id": "Standard_D4ads_v5",
                "driver_node_type_id": "Standard_D4ads_v5",
                "autotermination_minutes": 60,
                "enable_elastic_disk": true,
                "enable_local_disk_encryption": false,
                "runtime_engine": "STANDARD"
            }' > artifacts/cluster-output.json
            
            # Display cluster output
            cat artifacts/cluster-output.json

      # Set Databricks cluster id environment variable
      - name: Set Databricks environment variables
        run: |
          echo "DATABRICKS_CLUSTER_ID=$(jq .cluster_id artifacts/cluster-output.json -r)" >> $GITHUB_ENV

      # Upload files to DBFS
      # - name: upload-dbfs-temp
      #   uses: databricks/upload-dbfs-temp@v0
      #   id: upload-data
      #   with:
      #     local-path: databricks/data/curated.csv
      #     databricks-host: ${{ env.DATABRICKS_HOST }}
      #     databricks-token: ${{ env.DATABRICKS_TOKEN }}

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh

      - name: Databricks CLI config
        run: |
          cat > ~/.databrickscfg << EOF 
          [DEFAULT] 
          host = ${{ env.DATABRICKS_HOST }} 
          token = ${{ env.DATABRICKS_TOKEN }} 
          EOF

      # Upload files to DBFS
      - name: Upload data to dbfs
        run: |
          databricks fs mkdir dbfs:/FileStore/tables/credit-card-default-uci-curated
          databricks fs cp -r databricks/data/curated.csv dbfs:/FileStore/tables/credit-card-default-uci-curated/01.csv

      # Trigger notebook to create external tables
      - name: Create external tables
        uses: databricks/run-notebook@v0
        with:
          databricks-host: ${{ env.DATABRICKS_HOST }}
          databricks-token: ${{ env.DATABRICKS_TOKEN }}
          local-notebook-path: databricks/src/00-create-external-table.ipynb
          existing-cluster-id: ${{ env.DATABRICKS_CLUSTER_ID }}
          notebook-params-json: >
            {
              "path": "dbfs:/FileStore/tables/credit-card-default-uci-curated"
            }
      - name: Set GitHub repository variables
        env:
          DATABASE_HOST: ${{ env.DATABRICKS_HOST }}
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          # Add Databricks host to GitHub repository variables
          gh variable set DATABRICKS_HOST --body "$DATABASE_HOST"

          # Add user assigned identity name to GitHub repository variables
          gh variable set USER_ASSIGNED_IDENTITY_NAME \
            --body $(jq .properties.outputs.userAssignedIdentityName.value deployment-output.json)

          # Add container registry name to GitHub repository variables
          gh variable set CONTAINER_REGISTRY_NAME \
            --body $(jq .properties.outputs.containerRegistryName.value deployment-output.json)

          # Add container apps environment names to GitHub repository variables for staging environment
          gh variable set CONTAINER_APPS_ENVIRONMENT_NAME \
            --body $(jq .properties.outputs.containerAppEnvironmnetStagingName.value deployment-output.json) \
            --env staging

          # Add container apps environment names to GitHub repository variables for production environment
          gh variable set CONTAINER_APPS_ENVIRONMENT_NAME \
            --body $(jq .properties.outputs.containerAppEnvironmnetProductionName.value deployment-output.json) \
            --env production
